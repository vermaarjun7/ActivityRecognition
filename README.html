<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Practical Machine Learning</title>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}

pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Practical Machine Learning</h1>

<p>Course Project: Write Up</p>

<p>Research on activity recognition has traditionally focused on discriminating between different activities</p>

<h3>Objective</h3>

<p>To predict the quality of executing an activity through data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants.</p>

<h3>Data</h3>

<p>Six male participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Three-axes acceleration, gyroscope and magnetometer data from the accelerometers attached to different locations were recorded. The data also contain other derived statistics, e.g. mean, variance, standard deviation, max, min, amplitude, kurtosis and skewness, of the signals. With the outcome variable, <em>classe</em>, and user identification, there are total 160 variables in the data.</p>

<p>The training data, 19622 observations, are available here: 
<a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">PML Testing</a></p>

<p>The test data, 20 observations, are available here: 
<a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">PML Training</a></p>

<h3>Analysis Summary</h3>

<p>Without the codebook of the input data nor domain knowledge of the subject, I treated the features as they are, even though the data set probably should be separated into 2 data files: point-of-time versus aggregated level, b/c the derived features look like only populated when <em>new_windows = â€œyesâ€</em>, and might be derived from the same <em>window_num</em>. Only 6 out of 152 features in <em>new_windows = â€œyesâ€</em>  with NA rate more than 95% versus 100 out of 152 features with the same threshold in <em>new_windows = â€œnoâ€</em>. Anyhow, in the analysis, I focused on the 152 numeric-formatted features and treated them as they are in the input data file, i.e. excluded â€œwindowâ€, and time-related features.</p>

<p>The R script in the repo was designed to do following:</p>

<ul>
<li> Gave a quick check of data by separating them according to new vs. old windows. (The reason was explained as above.)</li>
<li> Cleaned up features with high missing/NA rate and those with single fixed value, i.e. variance = 0. Most of the derived features were removed in this step and left 51 features.</li>
<li> Further split <em>training</em> into two data sets: <em>Train</em> and <em>Test</em> with 70-30 split to detect overfitting.</li>
<li> Created a stratified sample to plot the features. Several features were highly correlated with others. Either compressing the data or further feature selection is required. I didn&#39;t choose compressing data because it&#39;s hard to explain the components.</li>
</ul>


<ul>
<li><p> </p>

<ul>
<li>Selected features through recursive feature eliminating (backward). The <em>Train</em> data set were normalized first (unnecessary step b/c random forest supposes to be invariant to the magnitude, but I&#39;ve done this step, ran the selection  and it was pretty long runtime.), and then correlation was checking again through findCorrelation in <em>caret</em> package. And, then through rfeControl func = rfFunctions to calculate variable importance using random forest. Figure below suggests ~15 features probably are sufficient to give us good accuracy.</li>
</ul></li>
</ul>

<p><img src="data:image/png;base64,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" alt="plot2 NumberFeatures"/></p>

<pre><code class="sh">&gt; Top15.features
 [1] &quot;yaw_belt&quot;          &quot;magnet_dumbbell_z&quot; &quot;pitch_forearm&quot;     &quot;magnet_dumbbell_y&quot; 
 [5] &quot;roll_forearm&quot;      &quot;magnet_dumbbell_x&quot; &quot;magnet_belt_y&quot;     &quot;magnet_belt_z&quot;
 [9] &quot;accel_dumbbell_y&quot;  &quot;roll_dumbbell&quot;     &quot;gyros_belt_z&quot;      &quot;roll_arm&quot;     
[13] &quot;total_accel_belt&quot;  &quot;accel_forearm_x&quot;   &quot;magnet_forearm_z&quot; 
</code></pre>

<ul>
<li>Used <em>randomForest</em> to train the selected features against <em>classe</em>. The in-sample error is ~1.3%.</li>
</ul>

<pre><code class="sh">&gt; modFit.rf
        OOB estimate of  error rate: 1.27%
Confusion matrix:
     A    B    C    D    E class.error
A 3893    6    3    2    2 0.003328213
B   26 2597   30    5    0 0.022949586
C    0   33 2351   11    1 0.018781302
D    1    5   31 2211    4 0.018206039
E    0    1    7    7 2510 0.005940594

</code></pre>

<ul>
<li>Applied the model to <em>Test</em> data (30% hold-out). The out-of-sample error is estimated ~1.5%, which is not too off from the in-sample error 1.3%</li>
</ul>

<pre><code class="sh">&gt; confusionMatrix(pred, Test1[,1]) #accuray = 0.985 sample error rate ~ 1.5%
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1669   10    0    0    0
         B    0 1105   18    0    0
         C    2   17 1000   18    0
         D    3    7    8  946    5
         E    0    0    0    0 1077

Overall Statistics

               Accuracy : 0.985          
                 95% CI : (0.9816, 0.988)
    No Information Rate : 0.2845         
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16   
</code></pre>

<ul>
<li> Applied the model to 20 observations from Testing data set, and submitted the answers (received 20/20).</li>
</ul>

<pre><code class="sh">&gt; predict(modFit.rf, x.outdata)
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
</code></pre>

</body>

</html>
